<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Running Local Cloudflare Workers to Gather News Information - Part 3 | Just a Guy, from Kenya</title>
<meta name="keywords" content="cloudflare, workers, web scraping, typescript, serverless">
<meta name="description" content="Introduction
In the first part of this series, we explored the basics of Cloudflare Workers and set up our project. The second part covered core implementation details like cookie management and article parsing.
Now, in this final installment, we&rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:

Multiple pattern matching techniques for resilient scraping
Comprehensive debugging endpoints
Deployment strategies and maintenance considerations

Multiple Pattern Matching for Robust Scraping
One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.">
<meta name="author" content="">
<link rel="canonical" href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.guyfromtheke.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.guyfromtheke.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.guyfromtheke.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.guyfromtheke.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.guyfromtheke.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/">
  <meta property="og:site_name" content="Just a Guy, from Kenya">
  <meta property="og:title" content="Running Local Cloudflare Workers to Gather News Information - Part 3">
  <meta property="og:description" content="Introduction In the first part of this series, we explored the basics of Cloudflare Workers and set up our project. The second part covered core implementation details like cookie management and article parsing.
Now, in this final installment, we’ll dive into the advanced features that make our news scraping worker robust and maintainable:
Multiple pattern matching techniques for resilient scraping Comprehensive debugging endpoints Deployment strategies and maintenance considerations Multiple Pattern Matching for Robust Scraping One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-07T22:54:51+03:00">
    <meta property="article:modified_time" content="2025-04-07T22:54:51+03:00">
    <meta property="article:tag" content="Cloudflare">
    <meta property="article:tag" content="Workers">
    <meta property="article:tag" content="Web Scraping">
    <meta property="article:tag" content="Typescript">
    <meta property="article:tag" content="Serverless">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Running Local Cloudflare Workers to Gather News Information - Part 3">
<meta name="twitter:description" content="Introduction
In the first part of this series, we explored the basics of Cloudflare Workers and set up our project. The second part covered core implementation details like cookie management and article parsing.
Now, in this final installment, we&rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:

Multiple pattern matching techniques for resilient scraping
Comprehensive debugging endpoints
Deployment strategies and maintenance considerations

Multiple Pattern Matching for Robust Scraping
One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://www.guyfromtheke.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Running Local Cloudflare Workers to Gather News Information - Part 3",
      "item": "https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Running Local Cloudflare Workers to Gather News Information - Part 3",
  "name": "Running Local Cloudflare Workers to Gather News Information - Part 3",
  "description": "Introduction In the first part of this series, we explored the basics of Cloudflare Workers and set up our project. The second part covered core implementation details like cookie management and article parsing.\nNow, in this final installment, we\u0026rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:\nMultiple pattern matching techniques for resilient scraping Comprehensive debugging endpoints Deployment strategies and maintenance considerations Multiple Pattern Matching for Robust Scraping One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.\n",
  "keywords": [
    "cloudflare", "workers", "web scraping", "typescript", "serverless"
  ],
  "articleBody": "Introduction In the first part of this series, we explored the basics of Cloudflare Workers and set up our project. The second part covered core implementation details like cookie management and article parsing.\nNow, in this final installment, we’ll dive into the advanced features that make our news scraping worker robust and maintainable:\nMultiple pattern matching techniques for resilient scraping Comprehensive debugging endpoints Deployment strategies and maintenance considerations Multiple Pattern Matching for Robust Scraping One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.\nThe Problem with Single Pattern Matching Initially, I used a simple regex pattern to extract articles:\nconst articleRegex = /(.*?)\u003c\\/a\u003e/g; This worked fine until the site changed their HTML structure, causing the worker to return zero results. Instead of constantly updating the regex when the site changes, I implemented a more robust approach.\nImplementing Multiple Pattern Strategy The core of this approach is a function called tryMultiplePatterns that attempts several different extraction methods in succession:\nasync function tryMultiplePatterns(html: string, env: Env): Promise\u003c{ title: string; url: string }[]\u003e { // Store sample data for debugging await env.KV.put(\"debug_html_sample\", html.substring(0, 10000)); await env.KV.put(\"debug_timestamp\", new Date().toISOString()); // Try multiple approaches to extract articles... } The function includes three distinct approaches:\nArticle Element Parsing: First, it tries to find all elements and extract title/URL pairs from them H3 Teaser Parsing: If that fails, it looks for heading elements with specific classes Broad Pattern Fallback: As a last resort, it uses a more general pattern to capture content Here’s how the first approach looks:\n// Find all article elements const articleElements = []; const articleRegex = /]*\u003e([\\s\\S]*?)\u003c\\/article\u003e/gi; let articleMatch; while ((articleMatch = articleRegex.exec(html)) !== null) { articleElements.push(articleMatch[0]); } // Process each article element for (const articleHtml of articleElements) { try { // Extract URL and title from the article element const urlMatch = articleHtml.match(/]*href=\"([^\"]*)\"[^\u003e]*\u003e/); if (!urlMatch) continue; const titleMatch = articleHtml.match(/]*\u003e([\\s\\S]*?)\u003c\\/h3\u003e/); if (!titleMatch) continue; // Clean up the title... articles.push({ url: urlMatch[1].startsWith(\"http\") ? urlMatch[1] : `https://nation.africa${urlMatch[1]}`, title: title }); } catch (error) { console.error(\"Error processing article element:\", error); } } Post-Processing for Quality Results After extracting articles with any of the methods, I apply additional filtering to ensure quality results:\n// Filter out navigation links const filteredArticles = articles.filter(article =\u003e { // Skip navigation links which typically contain just a single word or section name const isNavigationLink = article.title.trim().split(/\\s+/).length \u003c= 2 \u0026\u0026 (article.url.includes(\"/news/\") || article.url.includes(\"/section/\") || article.url.includes(\"/category/\")); return !isNavigationLink; }); // Remove duplicates by URL const uniqueArticles = Array.from( new Map(filteredArticles.map(article =\u003e [article.url, article])).values() ); This multi-pattern approach with post-processing ensures that our worker continues to extract articles even when the site undergoes design changes. If one pattern fails, another will likely succeed.\nComprehensive Debugging Endpoints For a production service, especially one that runs on a schedule, having robust debugging capabilities is crucial. I implemented several endpoints to help diagnose issues without having to deploy new code.\nDebug Endpoint The most powerful debugging feature is a dedicated /debug endpoint that provides comprehensive information about the current state:\nif (url.pathname === \"/debug\") { try { const cookie = await getSessionCookie(env); console.log(\"Using cookie (first 30 chars):\", cookie.substring(0, 30) + \"...\"); const response = await fetch(NEWS_URL, { headers: { \"Cookie\": cookie, \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\" }, }); console.log(\"Article fetch response status:\", response.status); if (!response.ok) { const text = await response.text(); console.error(\"Error response preview:\", text.substring(0, 200) + \"...\"); throw new Error(`Failed to fetch articles: ${response.status}`); } const html = await response.text(); const articles = await tryMultiplePatterns(html, env); return new Response(JSON.stringify({ status: \"success\", articleCount: articles.length, articles: articles, debugInfo: { responseStatus: response.status, htmlLength: html.length, timestamp: new Date().toISOString() } }), { status: 200, headers: { \"Content-Type\": \"application/json\" }, }); } catch (error) { return new Response(JSON.stringify({ error: \"Debug failed\", details: error.message }), { status: 500, headers: { \"Content-Type\": \"application/json\" } }); } } This endpoint not only fetches and processes articles but also returns detailed diagnostic information including:\nResponse status from the news site Number of articles found Full article data HTML length Timestamp of the request Storing Debug Information in KV In addition to the real-time debug endpoint, I store samples of key data in KV storage for later analysis:\n// Store a sample of the HTML in KV for debugging await env.KV.put(\"debug_html_sample\", html.substring(0, 10000)); await env.KV.put(\"debug_timestamp\", new Date().toISOString()); // Store h3 samples for debugging const h3Tags = html.match(/]*\u003e.*?\u003c\\/h3\u003e/gs) || []; await env.KV.put(\"debug_h3_samples\", h3Tags.slice(0, 10).join('\\n\\n')); // Store some article elements for debugging await env.KV.put(\"debug_article_elements\", articleElements.slice(0, 5).join('\\n\\n---\\n\\n')); await env.KV.put(\"debug_article_count\", articleElements.length.toString()); // Store extracted articles await env.KV.put(\"debug_extracted_articles\", JSON.stringify({ count: articles.length, articles: articles.slice(0, 20) // Store first 20 articles for debugging })); This approach creates a historical record that can be examined if issues arise later, even if they’re intermittent or cannot be reproduced on demand.\nDeployment and Maintenance Considerations Running a Cloudflare Worker in production requires careful thought about deployment, monitoring, and maintenance.\nDeployment Strategy For deploying the worker, I use Wrangler’s deployment capabilities:\n# Deploy to production wrangler deploy However, to ensure reliable deployments, I’ve implemented a few best practices:\nVersion Control: All changes are committed to git before deployment Environment Variables: Sensitive information is stored as environment variables or KV entries Testing: Local testing before deployment using wrangler dev Monitoring and Alerting Cloudflare provides basic monitoring for Workers, but for more comprehensive monitoring, consider:\nSetting up status checks that ping your worker endpoints Implementing a logging service to capture console logs Creating a dashboard for KV storage status I’ve implemented simple self-monitoring through KV storage timestamps that track when the worker last ran successfully.\nCookie Management Maintenance The most maintenance-intensive part of this worker is cookie management. Since cookies expire and login methods can change, I’ve separated this concern:\nExternal Cookie Management: Using a separate extract-cookies.js script for refreshing cookies Cookie Expiration Checks: Regular checks to warn about soon-to-expire cookies Manual Refresh Process: Documented steps for updating cookies when needed Here’s the workflow I use for cookie maintenance:\n1. Run the extract-cookies.js script locally: node extract-cookies.js 2. The script: - Opens a headless browser - Navigates to the login page - Completes authentication - Extracts cookies - Updates the Worker's KV storage 3. Verify with the /cookie-status endpoint This separation of concerns makes maintenance more manageable, as the cookie extraction process can be updated independently of the worker logic.\nHandling Site Changes News sites change frequently, and here’s my strategy for dealing with that:\nMonitor Extraction Results: Set up regular checks of article count Update Patterns as Needed: If extraction fails, add new patterns to the tryMultiplePatterns function Resilient Design: The multiple-pattern approach often adapts automatically Cost Considerations Cloudflare Workers offers generous free tier limits, but it’s good to be aware of usage:\n100,000 requests per day on the free plan 10ms CPU time per request (adequate for our parsing needs) KV storage limits (1GB storage, 100,000 reads/day, 1,000 writes/day) Our implementation uses minimal resources, scheduling runs only every 12 hours, keeping us well within free tier limits.\nConclusion Throughout this series, we’ve built a robust Cloudflare Worker that reliably collects news headlines from Nation Africa. We’ve implemented:\nA solid foundation with proper configuration and environment setup Reliable cookie management and article parsing Multiple pattern matching for resilience against site changes Comprehensive debugging capabilities Sensible deployment and maintenance practices This approach can be adapted to many other web scraping tasks where you need reliable, scheduled data collection with minimal maintenance overhead.\nThe complete code is available in my GitHub repository, and I hope this series has provided you with insights into building and maintaining serverless web scrapers using Cloudflare Workers.\nHappy coding!\n",
  "wordCount" : "1286",
  "inLanguage": "en",
  "datePublished": "2025-04-07T22:54:51+03:00",
  "dateModified": "2025-04-07T22:54:51+03:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Just a Guy, from Kenya",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.guyfromtheke.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.guyfromtheke.com/" accesskey="h" title="Just a Guy, from Kenya (Alt + H)">Just a Guy, from Kenya</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.guyfromtheke.com/about/" title="About">
                    <span>About Me</span>
                </a>
            </li>
            <li>
                <a href="https://www.guyfromtheke.com/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://www.guyfromtheke.com/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://www.guyfromtheke.com/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://www.guyfromtheke.com/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://www.guyfromtheke.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://www.guyfromtheke.com/">Home</a>&nbsp;»&nbsp;<a href="https://www.guyfromtheke.com/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Running Local Cloudflare Workers to Gather News Information - Part 3
    </h1>
    <div class="post-meta"><span title='2025-04-07 22:54:51 +0300 EAT'>April 7, 2025</span>&nbsp;·&nbsp;7 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#multiple-pattern-matching-for-robust-scraping" aria-label="Multiple Pattern Matching for Robust Scraping">Multiple Pattern Matching for Robust Scraping</a><ul>
                        
                <li>
                    <a href="#the-problem-with-single-pattern-matching" aria-label="The Problem with Single Pattern Matching">The Problem with Single Pattern Matching</a></li>
                <li>
                    <a href="#implementing-multiple-pattern-strategy" aria-label="Implementing Multiple Pattern Strategy">Implementing Multiple Pattern Strategy</a></li>
                <li>
                    <a href="#post-processing-for-quality-results" aria-label="Post-Processing for Quality Results">Post-Processing for Quality Results</a></li></ul>
                </li>
                <li>
                    <a href="#comprehensive-debugging-endpoints" aria-label="Comprehensive Debugging Endpoints">Comprehensive Debugging Endpoints</a><ul>
                        
                <li>
                    <a href="#debug-endpoint" aria-label="Debug Endpoint">Debug Endpoint</a></li>
                <li>
                    <a href="#storing-debug-information-in-kv" aria-label="Storing Debug Information in KV">Storing Debug Information in KV</a></li></ul>
                </li>
                <li>
                    <a href="#deployment-and-maintenance-considerations" aria-label="Deployment and Maintenance Considerations">Deployment and Maintenance Considerations</a><ul>
                        
                <li>
                    <a href="#deployment-strategy" aria-label="Deployment Strategy">Deployment Strategy</a></li>
                <li>
                    <a href="#monitoring-and-alerting" aria-label="Monitoring and Alerting">Monitoring and Alerting</a></li>
                <li>
                    <a href="#cookie-management-maintenance" aria-label="Cookie Management Maintenance">Cookie Management Maintenance</a></li>
                <li>
                    <a href="#handling-site-changes" aria-label="Handling Site Changes">Handling Site Changes</a></li>
                <li>
                    <a href="#cost-considerations" aria-label="Cost Considerations">Cost Considerations</a></li></ul>
                </li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>In the <a href="/posts/running-local-cloudflare-workers-news-part1">first part</a> of this series, we explored the basics of Cloudflare Workers and set up our project. The <a href="/posts/running-local-cloudflare-workers-news-part2">second part</a> covered core implementation details like cookie management and article parsing.</p>
<p>Now, in this final installment, we&rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:</p>
<ol>
<li>Multiple pattern matching techniques for resilient scraping</li>
<li>Comprehensive debugging endpoints</li>
<li>Deployment strategies and maintenance considerations</li>
</ol>
<h2 id="multiple-pattern-matching-for-robust-scraping">Multiple Pattern Matching for Robust Scraping<a hidden class="anchor" aria-hidden="true" href="#multiple-pattern-matching-for-robust-scraping">#</a></h2>
<p>One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.</p>
<h3 id="the-problem-with-single-pattern-matching">The Problem with Single Pattern Matching<a hidden class="anchor" aria-hidden="true" href="#the-problem-with-single-pattern-matching">#</a></h3>
<p>Initially, I used a simple regex pattern to extract articles:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">articleRegex</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">/&lt;h3 class=&#34;article-title.*?&#34;&gt;&lt;a href=&#34;(.*?)&#34;&gt;(.*?)&lt;\/a&gt;/g</span>;
</span></span></code></pre></div><p>This worked fine until the site changed their HTML structure, causing the worker to return zero results. Instead of constantly updating the regex when the site changes, I implemented a more robust approach.</p>
<h3 id="implementing-multiple-pattern-strategy">Implementing Multiple Pattern Strategy<a hidden class="anchor" aria-hidden="true" href="#implementing-multiple-pattern-strategy">#</a></h3>
<p>The core of this approach is a function called <code>tryMultiplePatterns</code> that attempts several different extraction methods in succession:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">function</span> <span style="color:#a6e22e">tryMultiplePatterns</span>(<span style="color:#a6e22e">html</span>: <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">env</span>: <span style="color:#66d9ef">Env</span>)<span style="color:#f92672">:</span> <span style="color:#a6e22e">Promise</span><span style="color:#f92672">&lt;</span>{ <span style="color:#a6e22e">title</span>: <span style="color:#66d9ef">string</span>; <span style="color:#a6e22e">url</span>: <span style="color:#66d9ef">string</span> }[]<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Store sample data for debugging
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_html_sample&#34;</span>, <span style="color:#a6e22e">html</span>.<span style="color:#a6e22e">substring</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">10000</span>));
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_timestamp&#34;</span>, <span style="color:#66d9ef">new</span> Date().<span style="color:#a6e22e">toISOString</span>());
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Try multiple approaches to extract articles...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>The function includes three distinct approaches:</p>
<ol>
<li><strong>Article Element Parsing</strong>: First, it tries to find all <code>&lt;article&gt;</code> elements and extract title/URL pairs from them</li>
<li><strong>H3 Teaser Parsing</strong>: If that fails, it looks for heading elements with specific classes</li>
<li><strong>Broad Pattern Fallback</strong>: As a last resort, it uses a more general pattern to capture content</li>
</ol>
<p>Here&rsquo;s how the first approach looks:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#75715e">// Find all article elements
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">articleElements</span> <span style="color:#f92672">=</span> [];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">articleRegex</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">/&lt;article[^&gt;]*&gt;([\s\S]*?)&lt;\/article&gt;/gi</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> <span style="color:#a6e22e">articleMatch</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> ((<span style="color:#a6e22e">articleMatch</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">articleRegex</span>.<span style="color:#a6e22e">exec</span>(<span style="color:#a6e22e">html</span>)) <span style="color:#f92672">!==</span> <span style="color:#66d9ef">null</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">articleElements</span>.<span style="color:#a6e22e">push</span>(<span style="color:#a6e22e">articleMatch</span>[<span style="color:#ae81ff">0</span>]);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Process each article element
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">const</span> <span style="color:#a6e22e">articleHtml</span> <span style="color:#66d9ef">of</span> <span style="color:#a6e22e">articleElements</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">try</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Extract URL and title from the article element
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">urlMatch</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">articleHtml</span>.<span style="color:#a6e22e">match</span>(<span style="color:#e6db74">/&lt;a[^&gt;]*href=&#34;([^&#34;]*)&#34;[^&gt;]*&gt;/</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span><span style="color:#a6e22e">urlMatch</span>) <span style="color:#66d9ef">continue</span>;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">titleMatch</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">articleHtml</span>.<span style="color:#a6e22e">match</span>(<span style="color:#e6db74">/&lt;h3[^&gt;]*&gt;([\s\S]*?)&lt;\/h3&gt;/</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span><span style="color:#a6e22e">titleMatch</span>) <span style="color:#66d9ef">continue</span>;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Clean up the title...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">articles</span>.<span style="color:#a6e22e">push</span>({
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">url</span>: <span style="color:#66d9ef">urlMatch</span>[<span style="color:#ae81ff">1</span>].<span style="color:#a6e22e">startsWith</span>(<span style="color:#e6db74">&#34;http&#34;</span>) <span style="color:#f92672">?</span> <span style="color:#a6e22e">urlMatch</span>[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">:</span> <span style="color:#e6db74">`https://nation.africa</span><span style="color:#e6db74">${</span><span style="color:#a6e22e">urlMatch</span>[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">`</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">title</span>: <span style="color:#66d9ef">title</span>
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>  } <span style="color:#66d9ef">catch</span> (<span style="color:#a6e22e">error</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">console</span>.<span style="color:#a6e22e">error</span>(<span style="color:#e6db74">&#34;Error processing article element:&#34;</span>, <span style="color:#a6e22e">error</span>);
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="post-processing-for-quality-results">Post-Processing for Quality Results<a hidden class="anchor" aria-hidden="true" href="#post-processing-for-quality-results">#</a></h3>
<p>After extracting articles with any of the methods, I apply additional filtering to ensure quality results:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#75715e">// Filter out navigation links
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">filteredArticles</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">articles</span>.<span style="color:#a6e22e">filter</span>(<span style="color:#a6e22e">article</span> <span style="color:#f92672">=&gt;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Skip navigation links which typically contain just a single word or section name
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">isNavigationLink</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">article</span>.<span style="color:#a6e22e">title</span>.<span style="color:#a6e22e">trim</span>().<span style="color:#a6e22e">split</span>(<span style="color:#e6db74">/\s+/</span>).<span style="color:#a6e22e">length</span> <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">&amp;&amp;</span> 
</span></span><span style="display:flex;"><span>                         (<span style="color:#a6e22e">article</span>.<span style="color:#a6e22e">url</span>.<span style="color:#a6e22e">includes</span>(<span style="color:#e6db74">&#34;/news/&#34;</span>) <span style="color:#f92672">||</span> 
</span></span><span style="display:flex;"><span>                          <span style="color:#a6e22e">article</span>.<span style="color:#a6e22e">url</span>.<span style="color:#a6e22e">includes</span>(<span style="color:#e6db74">&#34;/section/&#34;</span>) <span style="color:#f92672">||</span> 
</span></span><span style="display:flex;"><span>                          <span style="color:#a6e22e">article</span>.<span style="color:#a6e22e">url</span>.<span style="color:#a6e22e">includes</span>(<span style="color:#e6db74">&#34;/category/&#34;</span>));
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> <span style="color:#f92672">!</span><span style="color:#a6e22e">isNavigationLink</span>;
</span></span><span style="display:flex;"><span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Remove duplicates by URL
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">uniqueArticles</span> <span style="color:#f92672">=</span> Array.<span style="color:#66d9ef">from</span>(
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">Map</span>(<span style="color:#a6e22e">filteredArticles</span>.<span style="color:#a6e22e">map</span>(<span style="color:#a6e22e">article</span> <span style="color:#f92672">=&gt;</span> [<span style="color:#a6e22e">article</span>.<span style="color:#a6e22e">url</span>, <span style="color:#a6e22e">article</span>])).<span style="color:#a6e22e">values</span>()
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div><p>This multi-pattern approach with post-processing ensures that our worker continues to extract articles even when the site undergoes design changes. If one pattern fails, another will likely succeed.</p>
<h2 id="comprehensive-debugging-endpoints">Comprehensive Debugging Endpoints<a hidden class="anchor" aria-hidden="true" href="#comprehensive-debugging-endpoints">#</a></h2>
<p>For a production service, especially one that runs on a schedule, having robust debugging capabilities is crucial. I implemented several endpoints to help diagnose issues without having to deploy new code.</p>
<h3 id="debug-endpoint">Debug Endpoint<a hidden class="anchor" aria-hidden="true" href="#debug-endpoint">#</a></h3>
<p>The most powerful debugging feature is a dedicated <code>/debug</code> endpoint that provides comprehensive information about the current state:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">url</span>.<span style="color:#a6e22e">pathname</span> <span style="color:#f92672">===</span> <span style="color:#e6db74">&#34;/debug&#34;</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">try</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">cookie</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">getSessionCookie</span>(<span style="color:#a6e22e">env</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">console</span>.<span style="color:#a6e22e">log</span>(<span style="color:#e6db74">&#34;Using cookie (first 30 chars):&#34;</span>, <span style="color:#a6e22e">cookie</span>.<span style="color:#a6e22e">substring</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">30</span>) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;...&#34;</span>);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">response</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">fetch</span>(<span style="color:#a6e22e">NEWS_URL</span>, {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">headers</span><span style="color:#f92672">:</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Cookie&#34;</span><span style="color:#f92672">:</span> <span style="color:#a6e22e">cookie</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;User-Agent&#34;</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#34;</span>
</span></span><span style="display:flex;"><span>      },
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">console</span>.<span style="color:#a6e22e">log</span>(<span style="color:#e6db74">&#34;Article fetch response status:&#34;</span>, <span style="color:#a6e22e">response</span>.<span style="color:#a6e22e">status</span>);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span><span style="color:#a6e22e">response</span>.<span style="color:#a6e22e">ok</span>) {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">text</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">response</span>.<span style="color:#a6e22e">text</span>();
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">console</span>.<span style="color:#a6e22e">error</span>(<span style="color:#e6db74">&#34;Error response preview:&#34;</span>, <span style="color:#a6e22e">text</span>.<span style="color:#a6e22e">substring</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">200</span>) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;...&#34;</span>);
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> Error(<span style="color:#e6db74">`Failed to fetch articles: </span><span style="color:#e6db74">${</span><span style="color:#a6e22e">response</span>.<span style="color:#a6e22e">status</span><span style="color:#e6db74">}</span><span style="color:#e6db74">`</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">html</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">response</span>.<span style="color:#a6e22e">text</span>();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">articles</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">tryMultiplePatterns</span>(<span style="color:#a6e22e">html</span>, <span style="color:#a6e22e">env</span>);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">Response</span>(<span style="color:#a6e22e">JSON</span>.<span style="color:#a6e22e">stringify</span>({
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">status</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;success&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">articleCount</span>: <span style="color:#66d9ef">articles.length</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">articles</span>: <span style="color:#66d9ef">articles</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">debugInfo</span><span style="color:#f92672">:</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">responseStatus</span>: <span style="color:#66d9ef">response.status</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">htmlLength</span>: <span style="color:#66d9ef">html.length</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">timestamp</span>: <span style="color:#66d9ef">new</span> Date().<span style="color:#a6e22e">toISOString</span>()
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }), {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">status</span>: <span style="color:#66d9ef">200</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">headers</span><span style="color:#f92672">:</span> { <span style="color:#e6db74">&#34;Content-Type&#34;</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;application/json&#34;</span> },
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>  } <span style="color:#66d9ef">catch</span> (<span style="color:#a6e22e">error</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">Response</span>(<span style="color:#a6e22e">JSON</span>.<span style="color:#a6e22e">stringify</span>({ 
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">error</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;Debug failed&#34;</span>, 
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">details</span>: <span style="color:#66d9ef">error.message</span> 
</span></span><span style="display:flex;"><span>    }), {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">status</span>: <span style="color:#66d9ef">500</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">headers</span><span style="color:#f92672">:</span> { <span style="color:#e6db74">&#34;Content-Type&#34;</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;application/json&#34;</span> }
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This endpoint not only fetches and processes articles but also returns detailed diagnostic information including:</p>
<ul>
<li>Response status from the news site</li>
<li>Number of articles found</li>
<li>Full article data</li>
<li>HTML length</li>
<li>Timestamp of the request</li>
</ul>
<h3 id="storing-debug-information-in-kv">Storing Debug Information in KV<a hidden class="anchor" aria-hidden="true" href="#storing-debug-information-in-kv">#</a></h3>
<p>In addition to the real-time debug endpoint, I store samples of key data in KV storage for later analysis:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-typescript" data-lang="typescript"><span style="display:flex;"><span><span style="color:#75715e">// Store a sample of the HTML in KV for debugging
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_html_sample&#34;</span>, <span style="color:#a6e22e">html</span>.<span style="color:#a6e22e">substring</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">10000</span>));
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_timestamp&#34;</span>, <span style="color:#66d9ef">new</span> Date().<span style="color:#a6e22e">toISOString</span>());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Store h3 samples for debugging
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">h3Tags</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">html</span>.<span style="color:#a6e22e">match</span>(<span style="color:#960050;background-color:#1e0010">/&lt;h3[^&gt;]*&gt;.*?&lt;\/h3&gt;/gs) || [];</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_h3_samples&#34;</span>, <span style="color:#a6e22e">h3Tags</span>.<span style="color:#a6e22e">slice</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">10</span>).<span style="color:#a6e22e">join</span>(<span style="color:#e6db74">&#39;\n\n&#39;</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Store some article elements for debugging
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_article_elements&#34;</span>, <span style="color:#a6e22e">articleElements</span>.<span style="color:#a6e22e">slice</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">5</span>).<span style="color:#a6e22e">join</span>(<span style="color:#e6db74">&#39;\n\n---\n\n&#39;</span>));
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_article_count&#34;</span>, <span style="color:#a6e22e">articleElements</span>.<span style="color:#a6e22e">length</span>.<span style="color:#a6e22e">toString</span>());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Store extracted articles
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">env</span>.<span style="color:#a6e22e">KV</span>.<span style="color:#a6e22e">put</span>(<span style="color:#e6db74">&#34;debug_extracted_articles&#34;</span>, <span style="color:#a6e22e">JSON</span>.<span style="color:#a6e22e">stringify</span>({
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">count</span>: <span style="color:#66d9ef">articles.length</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">articles</span>: <span style="color:#66d9ef">articles.slice</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">20</span>) <span style="color:#75715e">// Store first 20 articles for debugging
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}));
</span></span></code></pre></div><p>This approach creates a historical record that can be examined if issues arise later, even if they&rsquo;re intermittent or cannot be reproduced on demand.</p>
<h2 id="deployment-and-maintenance-considerations">Deployment and Maintenance Considerations<a hidden class="anchor" aria-hidden="true" href="#deployment-and-maintenance-considerations">#</a></h2>
<p>Running a Cloudflare Worker in production requires careful thought about deployment, monitoring, and maintenance.</p>
<h3 id="deployment-strategy">Deployment Strategy<a hidden class="anchor" aria-hidden="true" href="#deployment-strategy">#</a></h3>
<p>For deploying the worker, I use Wrangler&rsquo;s deployment capabilities:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Deploy to production</span>
</span></span><span style="display:flex;"><span>wrangler deploy
</span></span></code></pre></div><p>However, to ensure reliable deployments, I&rsquo;ve implemented a few best practices:</p>
<ol>
<li><strong>Version Control</strong>: All changes are committed to git before deployment</li>
<li><strong>Environment Variables</strong>: Sensitive information is stored as environment variables or KV entries</li>
<li><strong>Testing</strong>: Local testing before deployment using <code>wrangler dev</code></li>
</ol>
<h3 id="monitoring-and-alerting">Monitoring and Alerting<a hidden class="anchor" aria-hidden="true" href="#monitoring-and-alerting">#</a></h3>
<p>Cloudflare provides basic monitoring for Workers, but for more comprehensive monitoring, consider:</p>
<ul>
<li>Setting up status checks that ping your worker endpoints</li>
<li>Implementing a logging service to capture console logs</li>
<li>Creating a dashboard for KV storage status</li>
</ul>
<p>I&rsquo;ve implemented simple self-monitoring through KV storage timestamps that track when the worker last ran successfully.</p>
<h3 id="cookie-management-maintenance">Cookie Management Maintenance<a hidden class="anchor" aria-hidden="true" href="#cookie-management-maintenance">#</a></h3>
<p>The most maintenance-intensive part of this worker is cookie management. Since cookies expire and login methods can change, I&rsquo;ve separated this concern:</p>
<ol>
<li><strong>External Cookie Management</strong>: Using a separate <code>extract-cookies.js</code> script for refreshing cookies</li>
<li><strong>Cookie Expiration Checks</strong>: Regular checks to warn about soon-to-expire cookies</li>
<li><strong>Manual Refresh Process</strong>: Documented steps for updating cookies when needed</li>
</ol>
<p>Here&rsquo;s the workflow I use for cookie maintenance:</p>
<pre tabindex="0"><code>1. Run the extract-cookies.js script locally:
   node extract-cookies.js

2. The script:
   - Opens a headless browser
   - Navigates to the login page
   - Completes authentication
   - Extracts cookies
   - Updates the Worker&#39;s KV storage

3. Verify with the /cookie-status endpoint
</code></pre><p>This separation of concerns makes maintenance more manageable, as the cookie extraction process can be updated independently of the worker logic.</p>
<h3 id="handling-site-changes">Handling Site Changes<a hidden class="anchor" aria-hidden="true" href="#handling-site-changes">#</a></h3>
<p>News sites change frequently, and here&rsquo;s my strategy for dealing with that:</p>
<ol>
<li><strong>Monitor Extraction Results</strong>: Set up regular checks of article count</li>
<li><strong>Update Patterns as Needed</strong>: If extraction fails, add new patterns to the <code>tryMultiplePatterns</code> function</li>
<li><strong>Resilient Design</strong>: The multiple-pattern approach often adapts automatically</li>
</ol>
<h3 id="cost-considerations">Cost Considerations<a hidden class="anchor" aria-hidden="true" href="#cost-considerations">#</a></h3>
<p>Cloudflare Workers offers generous free tier limits, but it&rsquo;s good to be aware of usage:</p>
<ul>
<li>100,000 requests per day on the free plan</li>
<li>10ms CPU time per request (adequate for our parsing needs)</li>
<li>KV storage limits (1GB storage, 100,000 reads/day, 1,000 writes/day)</li>
</ul>
<p>Our implementation uses minimal resources, scheduling runs only every 12 hours, keeping us well within free tier limits.</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Throughout this series, we&rsquo;ve built a robust Cloudflare Worker that reliably collects news headlines from Nation Africa. We&rsquo;ve implemented:</p>
<ul>
<li>A solid foundation with proper configuration and environment setup</li>
<li>Reliable cookie management and article parsing</li>
<li>Multiple pattern matching for resilience against site changes</li>
<li>Comprehensive debugging capabilities</li>
<li>Sensible deployment and maintenance practices</li>
</ul>
<p>This approach can be adapted to many other web scraping tasks where you need reliable, scheduled data collection with minimal maintenance overhead.</p>
<p>The complete code is available in my GitHub repository, and I hope this series has provided you with insights into building and maintaining serverless web scrapers using Cloudflare Workers.</p>
<p>Happy coding!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://www.guyfromtheke.com/tags/cloudflare/">Cloudflare</a></li>
      <li><a href="https://www.guyfromtheke.com/tags/workers/">Workers</a></li>
      <li><a href="https://www.guyfromtheke.com/tags/web-scraping/">Web Scraping</a></li>
      <li><a href="https://www.guyfromtheke.com/tags/typescript/">Typescript</a></li>
      <li><a href="https://www.guyfromtheke.com/tags/serverless/">Serverless</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://www.guyfromtheke.com/posts/secure-kubernetes-cluster-upgrades/">
    <span class="title">« Prev</span>
    <br>
    <span>Secure Kubernetes Cluster Upgrades: A Step-by-Step Guide</span>
  </a>
  <a class="next" href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2/">
    <span class="title">Next »</span>
    <br>
    <span>Running Local Cloudflare Workers to Gather News Information - Part 2</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on x"
            href="https://x.com/intent/tweet/?text=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203&amp;url=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f&amp;hashtags=cloudflare%2cworkers%2cwebscraping%2ctypescript%2cserverless">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f&amp;title=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203&amp;summary=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203&amp;source=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f&title=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on whatsapp"
            href="https://api.whatsapp.com/send?text=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203%20-%20https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on telegram"
            href="https://telegram.me/share/url?text=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203&amp;url=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Running Local Cloudflare Workers to Gather News Information - Part 3 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Running%20Local%20Cloudflare%20Workers%20to%20Gather%20News%20Information%20-%20Part%203&u=https%3a%2f%2fwww.guyfromtheke.com%2fposts%2frunning-local-cloudflare-workers-news-part3%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><div class="comments">
    
    <script src="https://utteranc.es/client.js"
            repo="guyfromtheke/guyfromtheke"
            issue-term="pathname"
            label="comment"
            theme="preferred-color-scheme"
            crossorigin="anonymous"
            async>
    </script>
</div>



</article>
    </main>
    
<footer class="footer">
        <span>© <a href="https://github.com/adityatelange/hugo-PaperMod/graphs/contributors">PaperMod Contributors</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>

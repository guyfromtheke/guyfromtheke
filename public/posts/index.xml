<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Just a Guy, from Kenya</title><link>https://www.guyfromtheke.com/posts/</link><description>Recent content in Posts on Just a Guy, from Kenya</description><generator>Hugo -- 0.145.0</generator><language>en</language><copyright>PaperMod Contributors</copyright><lastBuildDate>Tue, 15 Apr 2025 04:26:00 +0300</lastBuildDate><atom:link href="https://www.guyfromtheke.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Secure Kubernetes Cluster Upgrades: A Step-by-Step Guide</title><link>https://www.guyfromtheke.com/posts/secure-kubernetes-cluster-upgrades/</link><pubDate>Tue, 15 Apr 2025 04:26:00 +0300</pubDate><guid>https://www.guyfromtheke.com/posts/secure-kubernetes-cluster-upgrades/</guid><description>&lt;h1 id="secure-kubernetes-cluster-upgrades-a-step-by-step-guide">Secure Kubernetes Cluster Upgrades: A Step-by-Step Guide&lt;/h1>
&lt;p>In this post, I&amp;rsquo;ll document a recent Kubernetes cluster upgrade process I implemented, focusing on security, automation, and best practices. I&amp;rsquo;ll walk through the entire process from environment assessment to verification, highlighting challenges and solutions along the way.&lt;/p>
&lt;h2 id="environment-overview">Environment Overview&lt;/h2>
&lt;p>Our setup consisted of a small K3s Kubernetes cluster running on Ubuntu 24.04 with:&lt;/p>
&lt;ul>
&lt;li>1 master node (control plane)&lt;/li>
&lt;li>2 worker nodes&lt;/li>
&lt;li>All nodes running an older kernel version (6.8.0-56-generic)&lt;/li>
&lt;li>Multiple security updates pending&lt;/li>
&lt;/ul>
&lt;h2 id="upgrade-objectives">Upgrade Objectives&lt;/h2>
&lt;ol>
&lt;li>Update all system packages across all nodes&lt;/li>
&lt;li>Apply kernel updates securely&lt;/li>
&lt;li>Minimize downtime by implementing a rolling upgrade&lt;/li>
&lt;li>Establish secure automation for future upgrades&lt;/li>
&lt;/ol>
&lt;h2 id="step-1-setting-up-secure-access">Step 1: Setting Up Secure Access&lt;/h2>
&lt;p>The first step was to establish secure, password-less authentication using SSH keys instead of using plaintext passwords.&lt;/p></description></item><item><title>Running Local Cloudflare Workers to Gather News Information - Part 3</title><link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/</link><pubDate>Mon, 07 Apr 2025 22:54:51 +0300</pubDate><guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In the &lt;a href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1">first part&lt;/a> of this series, we explored the basics of Cloudflare Workers and set up our project. The &lt;a href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2">second part&lt;/a> covered core implementation details like cookie management and article parsing.&lt;/p>
&lt;p>Now, in this final installment, we&amp;rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:&lt;/p>
&lt;ol>
&lt;li>Multiple pattern matching techniques for resilient scraping&lt;/li>
&lt;li>Comprehensive debugging endpoints&lt;/li>
&lt;li>Deployment strategies and maintenance considerations&lt;/li>
&lt;/ol>
&lt;h2 id="multiple-pattern-matching-for-robust-scraping">Multiple Pattern Matching for Robust Scraping&lt;/h2>
&lt;p>One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.&lt;/p></description></item><item><title>Running Local Cloudflare Workers to Gather News Information - Part 2</title><link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2/</link><pubDate>Mon, 07 Apr 2025 22:53:51 +0300</pubDate><guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In &lt;a href="https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1">Part 1&lt;/a>, we covered the basics of Cloudflare Workers and set up our project. Now, let&amp;rsquo;s dive into the core implementation details that make our news gathering worker function.&lt;/p>
&lt;p>This post focuses on three crucial aspects:&lt;/p>
&lt;ol>
&lt;li>Cookie management for authenticated access&lt;/li>
&lt;li>Article fetching and parsing techniques&lt;/li>
&lt;li>Error handling and debugging strategies&lt;/li>
&lt;/ol>
&lt;h2 id="cookie-management-system">Cookie Management System&lt;/h2>
&lt;p>Many modern websites, including Nation Africa, use cookies for session management and paywalls. To access full content, we need to maintain valid session cookies.&lt;/p></description></item><item><title>Running Local Cloudflare Workers to Gather News Information - Part 1</title><link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1/</link><pubDate>Mon, 07 Apr 2025 22:52:51 +0300</pubDate><guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1/</guid><description>&lt;h2 id="introduction-to-cloudflare-workers">Introduction to Cloudflare Workers&lt;/h2>
&lt;p>Cloudflare Workers represent a paradigm shift in how we build and deploy applications on the web. Unlike traditional server-based applications, Cloudflare Workers run on Cloudflare&amp;rsquo;s edge network, meaning they execute closer to your users and provide impressive performance benefits.&lt;/p>
&lt;p>Key advantages of Cloudflare Workers include:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Edge Execution&lt;/strong>: Code runs on Cloudflare&amp;rsquo;s global network, reducing latency&lt;/li>
&lt;li>&lt;strong>Serverless Architecture&lt;/strong>: No servers to manage or scale&lt;/li>
&lt;li>&lt;strong>Cost-Effective&lt;/strong>: Pay only for what you use with generous free tier&lt;/li>
&lt;li>&lt;strong>JavaScript/TypeScript Native&lt;/strong>: Write in familiar languages&lt;/li>
&lt;li>&lt;strong>Powerful API Access&lt;/strong>: Built-in fetch, KV storage, and more&lt;/li>
&lt;/ul>
&lt;p>In this series, I&amp;rsquo;ll walk through how I built a Cloudflare Worker that collects news articles from Nation Africa (&lt;a href="https://nation.africa">https://nation.africa&lt;/a>) for personal use, and how you might adapt this approach for other sites.&lt;/p></description></item><item><title>Managing Proxmox Containers with Terraform</title><link>https://www.guyfromtheke.com/posts/managing-proxmox-containers-with-terraform/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.guyfromtheke.com/posts/managing-proxmox-containers-with-terraform/</guid><description>A step-by-step guide on how to create and manage LXC containers in Proxmox using Terraform</description></item><item><title>My Website, finally! :)</title><link>https://www.guyfromtheke.com/posts/first/</link><pubDate>Sun, 16 Mar 2025 01:45:05 +0300</pubDate><guid>https://www.guyfromtheke.com/posts/first/</guid><description>&lt;h1 id="kinda-finally-did-it-">Kinda finally did it ?&lt;/h1>
&lt;p>So over the past few weeks I have been working on my homelab, and I have learnt sooo much along the way, and I figured, the best way to post about it was to write about it. So I wrote an article on linkedln &lt;a href="https://www.linkedin.com/pulse/project-home-lab-part-1-duncan-njoroge-k6roc/?trackingId=xvkKya%2FfRE%2BFavksulcKxw%3D%3D">https://www.linkedin.com/pulse/project-home-lab-part-1-duncan-njoroge-k6roc/?trackingId=xvkKya%2FfRE%2BFavksulcKxw%3D%3D&lt;/a> Which elicited a lot of interest. But I also not only wanted to document it there, I wanted to be able to share it to the world, so that when they search for something related to &amp;quot; how do I begin a homelab, they will find some footing.&lt;/p></description></item></channel></rss>
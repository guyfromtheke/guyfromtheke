<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Just a Guy, from Kenya</title>
    <link>https://www.guyfromtheke.com/posts/</link>
    <description>Recent content in Posts on Just a Guy, from Kenya</description>
    <generator>Hugo -- 0.146.7</generator>
    <language>en</language>
    <copyright>PaperMod Contributors</copyright>
    <lastBuildDate>Tue, 15 Apr 2025 04:26:00 +0300</lastBuildDate>
    <atom:link href="https://www.guyfromtheke.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Secure Kubernetes Cluster Upgrades: A Step-by-Step Guide</title>
      <link>https://www.guyfromtheke.com/posts/secure-kubernetes-cluster-upgrades/</link>
      <pubDate>Tue, 15 Apr 2025 04:26:00 +0300</pubDate>
      <guid>https://www.guyfromtheke.com/posts/secure-kubernetes-cluster-upgrades/</guid>
      <description>&lt;h1 id=&#34;secure-kubernetes-cluster-upgrades-a-step-by-step-guide&#34;&gt;Secure Kubernetes Cluster Upgrades: A Step-by-Step Guide&lt;/h1&gt;
&lt;p&gt;In this post, I&amp;rsquo;ll document a recent Kubernetes cluster upgrade process I implemented, focusing on security, automation, and best practices. I&amp;rsquo;ll walk through the entire process from environment assessment to verification, highlighting challenges and solutions along the way.&lt;/p&gt;
&lt;h2 id=&#34;environment-overview&#34;&gt;Environment Overview&lt;/h2&gt;
&lt;p&gt;Our setup consisted of a small K3s Kubernetes cluster running on Ubuntu 24.04 with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 master node (control plane)&lt;/li&gt;
&lt;li&gt;2 worker nodes&lt;/li&gt;
&lt;li&gt;All nodes running an older kernel version (6.8.0-56-generic)&lt;/li&gt;
&lt;li&gt;Multiple security updates pending&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;upgrade-objectives&#34;&gt;Upgrade Objectives&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Update all system packages across all nodes&lt;/li&gt;
&lt;li&gt;Apply kernel updates securely&lt;/li&gt;
&lt;li&gt;Minimize downtime by implementing a rolling upgrade&lt;/li&gt;
&lt;li&gt;Establish secure automation for future upgrades&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;step-1-setting-up-secure-access&#34;&gt;Step 1: Setting Up Secure Access&lt;/h2&gt;
&lt;p&gt;The first step was to establish secure, password-less authentication using SSH keys instead of using plaintext passwords.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Running Local Cloudflare Workers to Gather News Information - Part 3</title>
      <link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/</link>
      <pubDate>Mon, 07 Apr 2025 22:54:51 +0300</pubDate>
      <guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part3/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1&#34;&gt;first part&lt;/a&gt; of this series, we explored the basics of Cloudflare Workers and set up our project. The &lt;a href=&#34;https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2&#34;&gt;second part&lt;/a&gt; covered core implementation details like cookie management and article parsing.&lt;/p&gt;
&lt;p&gt;Now, in this final installment, we&amp;rsquo;ll dive into the advanced features that make our news scraping worker robust and maintainable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multiple pattern matching techniques for resilient scraping&lt;/li&gt;
&lt;li&gt;Comprehensive debugging endpoints&lt;/li&gt;
&lt;li&gt;Deployment strategies and maintenance considerations&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;multiple-pattern-matching-for-robust-scraping&#34;&gt;Multiple Pattern Matching for Robust Scraping&lt;/h2&gt;
&lt;p&gt;One of the biggest challenges in web scraping is handling website changes. News sites frequently update their layouts and HTML structure, which can break simple scraping approaches. To build a resilient solution, I implemented a multi-tiered approach to article extraction.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Running Local Cloudflare Workers to Gather News Information - Part 2</title>
      <link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2/</link>
      <pubDate>Mon, 07 Apr 2025 22:53:51 +0300</pubDate>
      <guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part2/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1&#34;&gt;Part 1&lt;/a&gt;, we covered the basics of Cloudflare Workers and set up our project. Now, let&amp;rsquo;s dive into the core implementation details that make our news gathering worker function.&lt;/p&gt;
&lt;p&gt;This post focuses on three crucial aspects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cookie management for authenticated access&lt;/li&gt;
&lt;li&gt;Article fetching and parsing techniques&lt;/li&gt;
&lt;li&gt;Error handling and debugging strategies&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;cookie-management-system&#34;&gt;Cookie Management System&lt;/h2&gt;
&lt;p&gt;Many modern websites, including Nation Africa, use cookies for session management and paywalls. To access full content, we need to maintain valid session cookies.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Running Local Cloudflare Workers to Gather News Information - Part 1</title>
      <link>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1/</link>
      <pubDate>Mon, 07 Apr 2025 22:52:51 +0300</pubDate>
      <guid>https://www.guyfromtheke.com/posts/running-local-cloudflare-workers-news-part1/</guid>
      <description>&lt;h2 id=&#34;introduction-to-cloudflare-workers&#34;&gt;Introduction to Cloudflare Workers&lt;/h2&gt;
&lt;p&gt;Cloudflare Workers represent a paradigm shift in how we build and deploy applications on the web. Unlike traditional server-based applications, Cloudflare Workers run on Cloudflare&amp;rsquo;s edge network, meaning they execute closer to your users and provide impressive performance benefits.&lt;/p&gt;
&lt;p&gt;Key advantages of Cloudflare Workers include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Edge Execution&lt;/strong&gt;: Code runs on Cloudflare&amp;rsquo;s global network, reducing latency&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Serverless Architecture&lt;/strong&gt;: No servers to manage or scale&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost-Effective&lt;/strong&gt;: Pay only for what you use with generous free tier&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JavaScript/TypeScript Native&lt;/strong&gt;: Write in familiar languages&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Powerful API Access&lt;/strong&gt;: Built-in fetch, KV storage, and more&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this series, I&amp;rsquo;ll walk through how I built a Cloudflare Worker that collects news articles from Nation Africa (&lt;a href=&#34;https://nation.africa&#34;&gt;https://nation.africa&lt;/a&gt;) for personal use, and how you might adapt this approach for other sites.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Managing Proxmox Containers with Terraform</title>
      <link>https://www.guyfromtheke.com/posts/managing-proxmox-containers-with-terraform/</link>
      <pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://www.guyfromtheke.com/posts/managing-proxmox-containers-with-terraform/</guid>
      <description>A step-by-step guide on how to create and manage LXC containers in Proxmox using Terraform</description>
    </item>
    <item>
      <title>My Website, finally! :)</title>
      <link>https://www.guyfromtheke.com/posts/first/</link>
      <pubDate>Sun, 16 Mar 2025 01:45:05 +0300</pubDate>
      <guid>https://www.guyfromtheke.com/posts/first/</guid>
      <description>&lt;h1 id=&#34;kinda-finally-did-it-&#34;&gt;Kinda finally did it ?&lt;/h1&gt;
&lt;p&gt;So over the past few weeks I have been working on my homelab, and I have learnt sooo much along the way, and I figured, the best way to post about it was to write about it. So I wrote an article on linkedln &lt;a href=&#34;https://www.linkedin.com/pulse/project-home-lab-part-1-duncan-njoroge-k6roc/?trackingId=xvkKya%2FfRE%2BFavksulcKxw%3D%3D&#34;&gt;https://www.linkedin.com/pulse/project-home-lab-part-1-duncan-njoroge-k6roc/?trackingId=xvkKya%2FfRE%2BFavksulcKxw%3D%3D&lt;/a&gt; Which elicited a lot of interest. But I also not only wanted to document it there, I wanted to be able to share it to the world, so that when they search for something related to &amp;quot; how do I begin a homelab, they will find some footing.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
